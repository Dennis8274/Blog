<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[JDK源码阅读之ReentrantLok]]></title>
    <url>%2Fb484f60f.html</url>
    <content type="text"><![CDATA[写在前面作者Doug Lea如此描述这个类：A reentrant mutual exclusion {@link java.util.concurrent.locks.Lock} with the same basic behavior and semantics as the implicit monitor lock accessed using {@code synchronized} methods and statements, but with extended capabilities.ReentrantLock是继承java.util.concurrent.locks.Lock的可重入互斥锁，它具有跟隐式监视器锁(Synchronized)同样语义，用于锁定一个方法或代码块，除此之外，它还有一些额外的功能。ReentrantLock锁，只能被一个线程持有，如果该线程持有的同时尝试去获取该ReentrantLock，会立即返回。当一个线程获取ReentrantLock，即调用lock时，只有当该锁未被其它线程持有时才能成功。看一下源码中的示例：12345678910111213class X &#123; private final ReentrantLock lock = new ReentrantLock(); // ... public void m() &#123; lock.lock(); // block until condition holds try &#123; // ... method body &#125; finally &#123; lock.unlock() &#125; &#125;&#125; 另外，还有个lock.newCondition api可以使用，看下面用法：12345678910111213141516171819202122232425public class Y &#123; private final ReentrantLock lock = new ReentrantLock(); private final Condition condition = lock.newCondition(); public void waitOn() &#123; lock.lock(); try &#123; condition.await(); &#125; catch (InterruptedException e) &#123; // ... &#125; finally &#123; lock.unlock(); &#125; &#125; public void signal() &#123; lock.lock(); try&#123; condition.signal(); // or condition.signalAll() &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 注意，condition使用需在持有lock时。 ReentrantLock.lock还是结合示例，看看整个流程是怎么串起来的。有如下两个构造函数：1234567public ReentrantLock() &#123; sync = new NonfairSync();&#125;public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 构造时通过传入一个boolean参数，可以实例化一个公平Lock。而这里的FairSync和NonfairSync是继承自内部类Sync，而Sync则继承自AQS。如下代码：Sync类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = -5179523762034025860L; /** * Performs &#123;@link java.util.concurrent.locks.Lock#lock&#125;. The main reason for subclassing * is to allow fast path for nonfair version. */ // 子类实现这个方法，以提供公平/非公平锁的功能 abstract void lock(); /** * Performs non-fair tryLock. tryAcquire is implemented in * subclasses, but both need nonfair try for trylock method. */ // 非公平地尝试获取锁 final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); // 利用AQS中的state变量表示锁的获取次数 int c = getState(); if (c == 0) &#123; // 目前所无持有者 if (compareAndSetState(0, acquires)) &#123; // 设置当前owner线程 // setExclusiveOwnerThread方法为AbstractOwnableSynchronizer类的方法 // 该类就一个私有变量Thread exclusiveOwnerThread // 用于表示互斥资源的互斥持有线程 setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; // 当前线程为锁的持有线程，即可重入 int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); // 直接设置state setState(nextc); return true; &#125; // 否则获取失败 return false; &#125; // 尝试释放 protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; // 只有state==0时，才能认为锁可以被释放 free = true; // 设置owner线程为null setExclusiveOwnerThread(null); &#125; // 设置state setState(c); return free; &#125; protected final boolean isHeldExclusively() &#123; // While we must in general read state before owner, // we don't need to do so to check if current thread is owner return getExclusiveOwnerThread() == Thread.currentThread(); &#125; // for api ReentranLock.newCondition final ConditionObject newCondition() &#123; return new ConditionObject(); &#125; // Methods relayed from outer class final Thread getOwner() &#123; return getState() == 0 ? null : getExclusiveOwnerThread(); &#125; final int getHoldCount() &#123; return isHeldExclusively() ? getState() : 0; &#125; final boolean isLocked() &#123; // 锁是否被持有，即需判断state是否等于0 return getState() != 0; &#125; /** * Reconstitutes the instance from a stream (that is, deserializes it). */ private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; s.defaultReadObject(); setState(0); // reset to unlocked state &#125;&#125; 内部抽象类Sync继承Sync，实现了一些基础功能，内部有个抽象方法lock。子类实现这个方法可提供公平/非公平锁的功能。NonFairSync类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778 static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; /** * Performs lock. Try immediate barge, backing up to normal * acquire on failure. */ final void lock() &#123; // cas 操作state if (compareAndSetState(0, 1)) // 获取成功，设置当前线程为owner线程 setExclusiveOwnerThread(Thread.currentThread()); else // state 不等于0， 锁已经被其他线程持有 // acquire为AQS内方法，如下解析 acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; // non fair模式，是直接调用Sync类的nonfairTryAcquire方法，如上Sync类的解析 return nonfairTryAcquire(acquires); &#125; &#125;// from AQS public final void acquire(int arg) &#123; // tryAcquire为FairSync/NonfairSync重写方法 if (!tryAcquire(arg) &amp;&amp; // 构造一个node入链表 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125;// from AQS// 给定mode构建node节点，入链表，返回当前节点 private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node; &#125;// from AQS// 获取锁 final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); // 前驱为头结点 // tryAcquire为FairSync/NonfairSync重写方法 if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 已获取，设置当前node为head // 唤醒总是唤醒头结点的下一节点线程 setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; // 这里阻塞 LockSupport.park parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; FairSync类123456789101112131415161718192021222324252627282930313233343536static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; // 与Non fair的区别 // 调用AQS的acquire // 即先判断锁是否被持有，有没有前驱，如果持有是不是当前线程 // 然后再根据判断情况构造节点加入链表尾部，并阻塞。 acquire(1); &#125; /** * Fair version of tryAcquire. Don't grant access unless * recursive call or no waiters or is first. */ protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; // 与non fair 区别：是否有前驱，如有则获取失败 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; &#125;&#125; 以上代码分析，非公平锁，通过cas操作state去获取锁，即0-&gt;1，如果获取失败，则再次尝试(cas操作state，持有者是否为当前线程)，如果仍然获取失败，则构造一个node并接入链表尾部，并阻塞当前线程直到被唤醒。公平锁则不会直接去获取锁，而是在非公平锁基础上，会先查看链表是否有前驱，有则阻塞并构造新节点加入链表尾部。辅助下面的图看源码可能会有帮助。非公平锁：公平锁： ReentrantLock.unlock释放锁的逻辑相对获取锁要简短很多。unlock方法就是调用AQS的release方法： 1234567891011121314151617public final boolean release(int arg) &#123; // 尝试释放锁 Sync实现tryRelease,见如上Sync类解析 // 即state减arg,如果state减为0，则释放锁（owner线程置null） // 另外，这里AQS的state表示持有锁的次数 if (tryRelease(arg)) &#123; // 释放成功 Node h = head; // 头结点不为空，说明当前线程入过链表，所以并且头结点的状态应该是SIGNAL // shouldParkAfterFailedAcquire这里修改node的状态 if (h != null &amp;&amp; h.waitStatus != 0) // 唤醒下一节点线程，还记得获取锁的时候，线程节点入链表之后阻塞的位置是哪里吗？ // 在AQS里的acquireQueued这个方法 unparkSuccessor(h); return true; &#125; return false;&#125; ReentrantLock.newCondition接下来看一下newCondition这个api的内部流程是什么样的。ReentrantLock.newCondition方法内部调用Sync类实现的newCondition方法，而这个方法是实例化一个AQS的ConditionObject类对象:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143final ConditionObject newCondition() &#123; return new ConditionObject();&#125; public class ConditionObject implements Condition, java.io.Serializable &#123; /** First node of condition queue. */ private transient Node firstWaiter; /** Last node of condition queue. */ private transient Node lastWaiter; public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 添加一个condition节点，见下面该方法解析 Node node = addConditionWaiter(); // 释放所有获取次数记录，置state为0，见下面该方法解析 // 注意这里，调用condition.await时，是在lock块内 int savedState = fullyRelease(node); int interruptMode = 0; // isOnSyncQueue判断是否在Sync队列里，见下面该方法解析 while (!isOnSyncQueue(node)) &#123; // 阻塞在这里，直到signal唤醒 // signal唤醒后，isOnSyncQueue返回true，调出循环 LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; // acquireQueued见上面Sync对应方法解析，方法里的这里的queue指Sync的队列 // 这个队列会在signal唤醒时构造 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); &#125; private Node addConditionWaiter() &#123; Node t = lastWaiter; // If lastWaiter is cancelled, clean out. if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node; &#125; // 删除一些取消的节点 private void unlinkCancelledWaiters() &#123; Node t = firstWaiter; Node trail = null; while (t != null) &#123; Node next = t.nextWaiter; if (t.waitStatus != Node.CONDITION) &#123; t.nextWaiter = null; if (trail == null) firstWaiter = next; else trail.nextWaiter = next; if (next == null) lastWaiter = trail; &#125; else // 上一节点 trail = t; t = next; &#125; &#125; public final void signal() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first); &#125; public final void signalAll() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignalAll(first); &#125; // ... 省略其他代码 &#125;// from AQS final int fullyRelease(Node node) &#123; boolean failed = true; try &#123; int savedState = getState(); // 置state为0 if (release(savedState)) &#123; failed = false; return savedState; &#125; else &#123; throw new IllegalMonitorStateException(); &#125; &#125; finally &#123; if (failed) node.waitStatus = Node.CANCELLED; &#125; &#125; public final boolean release(int arg) &#123; // 尝试释放，置state -= arg，结合上下文，也就是state=0 if (tryRelease(arg)) &#123; Node h = head; // 这里h为null，waitState为CONDITION // 因为condition的api使用要求都在lock块内，所以h必定为null if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125;// node是否在Sync等待队列里(也就是调用了condition.signal，将waitStatus置为SIGNAL)// 根据waitStatus以及队列元素比较 final boolean isOnSyncQueue(Node node) &#123; if (node.waitStatus == Node.CONDITION || node.prev == null) return false; if (node.next != null) // If has successor, it must be on queue return true; /* * node.prev can be non-null, but not yet on queue because * the CAS to place it on queue can fail. So we have to * traverse from tail to make sure it actually made it. It * will always be near the tail in calls to this method, and * unless the CAS failed (which is unlikely), it will be * there, so we hardly ever traverse much. */ return findNodeFromTail(node); &#125; await方法的比较复杂，需要仔细梳理下，并且结合signal的流程才能清晰起来。以下为signal的流程： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class ConditionObject implements Condition, java.io.Serializable &#123; public final void signal() &#123; // 如果本线程不是持有锁线程，则throw if (!isHeldExclusively()) throw new IllegalMonitorStateException(); // 还记得吗，firstWaiter为condition队列里的头结点 Node first = firstWaiter; if (first != null) // 唤醒，结合上边await的流程看 // 就是改变waitStatus，以及入Sync队列 doSignal(first); &#125; private void doSignal(Node first) &#123; do &#123; if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; // transferForSIgnal改变first状态，并入Sync队列 &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); &#125;&#125;// from AQS final boolean transferForSignal(Node node) &#123; /* * If cannot change waitStatus, the node has been cancelled. */ if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; /* * Splice onto queue and try to set waitStatus of predecessor to * indicate that thread is (probably) waiting. If cancelled or * attempt to set waitStatus fails, wake up to resync (in which * case the waitStatus can be transiently and harmlessly wrong). */ // 入队，Sync的队列 Node p = enq(node); int ws = p.waitStatus; // 将waitStatus置为SIGNAL if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true; &#125; signal流程大致就是这样，signalAll其实就是从Condition头结点firstWaiter开始依次调用transferForSignal方法，大同小异。]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>JDK</tag>
        <tag>源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK源码阅读之Semaphore]]></title>
    <url>%2F61e94ea2.html</url>
    <content type="text"><![CDATA[写在前面作者Doug Lea如此描述这个类：A counting semaphore. Conceptually, a semaphore maintains a set of permits.顾名思义。计数信号量，它维护许可数量。acquire一个许可阻塞至池里有可用许可，release一个许可即往池里添加一个许可。如下为源码中示例代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243class Pool &#123; private static final int MAX_AVAILABLE = 100; private final Semaphore available = new Semaphore(MAX_AVAILABLE, true); public Object getItem() throws InterruptedException &#123; available.acquire(); return getNextAvailableItem(); &#125; public void putItem(Object x) &#123; if (markAsUnused(x)) available.release(); &#125; // Not a particularly efficient data structure; just for demo protected Object[] items = ... whatever kinds of items being managed protected boolean[] used = new boolean[MAX_AVAILABLE]; protected synchronized Object getNextAvailableItem() &#123; for (int i = 0; i &lt; MAX_AVAILABLE; ++i) &#123; if (!used[i]) &#123; used[i] = true; return items[i]; &#125; &#125; return null; // not reached &#125; protected synchronized boolean markAsUnused(Object item) &#123; for (int i = 0; i &lt; MAX_AVAILABLE; ++i) &#123; if (item == items[i]) &#123; if (used[i]) &#123; used[i] = false; return true; &#125; else return false; &#125; &#125; return false; &#125; &#125;&#125; 如上，示例中用到的api就两个，即acquire和release，意为获取一个许可及释放一个许可。 Sync变量内部抽象类Sync继承自AQS，用AQS中的volatile int state变量表示许可数量。Sync的子类有两个版本，fair和nonfair。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 1192457210091910933L; Sync(int permits) &#123; // state 表示当前许可数量 setState(permits); &#125; final int getPermits() &#123; return getState(); &#125; // 非公平式获取许可，cas操作，state减去acquires final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; int available = getState(); int remaining = available - acquires; // 注意这里remaining &lt; 0 if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125; // 释放许可就是state + releases protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; int current = getState(); int next = current + releases; if (next &lt; current) // overflow throw new Error("Maximum permit count exceeded"); if (compareAndSetState(current, next)) return true; &#125; &#125; final void reducePermits(int reductions) &#123; for (;;) &#123; int current = getState(); int next = current - reductions; if (next &gt; current) // underflow throw new Error("Permit count underflow"); if (compareAndSetState(current, next)) return; &#125; &#125; final int drainPermits() &#123; for (;;) &#123; int current = getState(); if (current == 0 || compareAndSetState(current, 0)) return current; &#125; &#125;&#125;static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = -2694183684443567898L; NonfairSync(int permits) &#123; super(permits); &#125; protected int tryAcquireShared(int acquires) &#123; // 非公平式获取许可，调用父类（Sync）的nonfairTryAcquireShared return nonfairTryAcquireShared(acquires); &#125;&#125;static final class FairSync extends Sync &#123; private static final long serialVersionUID = 2014338818796000944L; FairSync(int permits) &#123; super(permits); &#125; protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; // 先查看有没有前驱在阻塞等着获取许可，如果有，当前线程获取失败 // 这就是跟非公平的区别 if (hasQueuedPredecessors()) return -1; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125;&#125; Sync的两个子类，NonfairSync和FairSync，分别表示在获取许可时是非公平式（抢占式）和公平式。 Semaphore.acquire获取许可，调用Sync.acquireSharedInterruptibly(1)。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 调用内部实现类tryAcquireShared if (tryAcquireShared(arg) &lt; 0) // 池中许可数量小于0，即state&lt;0 doAcquireSharedInterruptibly(arg);&#125;private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; // 在链表尾部添加一个node表示当前阻塞的节点 // 注意头结点为一个标识节点，如下addWaiter方法 final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; // 前驱 final Node p = node.predecessor(); if (p == head) &#123; // 调用内部类（fair or nonfair）实现tryAcquireShared，获取许可 int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; // 许可数量恢复&gt;0，设置当前节点为头节点并且唤醒下一节点 setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; // 没有许可可获取，阻塞在这里，等待唤醒 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // 链表中没有前驱 enq(node); return node;&#125;private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) // 先要设置一个"空"头结点 tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 需要注意，当没有阻塞的节点时，即链表为空，这时往链表添加节点时是往一个”空”头节点后添加。唤醒时，在阻塞位置恢复再次循环，如果前驱是头结点且当前池中有许可，那么设置当前节点为头结点，并唤醒下一节点，否则再次阻塞。 Semaphore.release调用Sync.releaseShared(1)。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public final boolean releaseShared(int arg) &#123; // sync中的tryReleaseShared, state += arg if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125;private void doReleaseShared() &#123; /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. */ for (;;) &#123; Node h = head; // 如果有阻塞的节点 if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; // 阻塞时，在shouldParkAfterFailedAcquire这个方法里，将node的前驱已经设置为SIGNAL if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases // 唤醒h的下一节点，如下unparkSuccessor分析 unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125;private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; // 从后往前找，去掉已经cancel的节点，见AQS类waitStatus的可取类型 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) // 唤醒node的下一可用节点 LockSupport.unpark(s.thread);&#125; 唤醒时总是唤醒头结点的下一节点。注意waitStatus这个状态，在阻塞时，会在shouldParkAfterFailedAcquire这个方法里，将当前阻塞节点的前缀设置为SIGNAL。]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>JDK</tag>
        <tag>源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK源码阅读之CyclicBarrier]]></title>
    <url>%2F97e68def.html</url>
    <content type="text"><![CDATA[写在前面作者Doug Lea如此描述这个类：A synchronization aid that allows a set of threads to all wait for each other to reach a common barrier point.这也是一个多线程协调的辅助工具类。barrier可翻译为栅栏，顾名思义，这个类控制先到的线程则在”栅栏”处等待其他线程，直到所有线程都到达，再接着往下执行。此外，CyclicBarrier如其名，是循环可复用的。如下是源码中给出的示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Solver &#123; final int N; final float[][] data; final CyclicBarrier barrier; class Worker implements Runnable &#123; int myRow; Worker(int row) &#123; myRow = row; &#125; public void run() &#123; while (!done()) &#123; processRow(myRow); try &#123; // 等待一行处理结束 barrier.await(); &#125; catch (InterruptedException ex) &#123; return; &#125; catch (BrokenBarrierException ex) &#123; return; &#125; &#125; &#125; &#125; public Solver(float[][] matrix) &#123; data = matrix; N = matrix.length; // 所有行处理完，再merge Runnable barrierAction = new Runnable() &#123; public void run() &#123; mergeRows(...); &#125;&#125;; barrier = new CyclicBarrier(N, barrierAction); List&lt;Thread&gt; threads = new ArrayList&lt;Thread&gt;(N); for (int i = 0; i &lt; N; i++) &#123; Thread thread = new Thread(new Worker(i)); threads.add(thread); thread.start(); &#125; // wait until done for (Thread thread : threads) thread.join(); &#125; &#125;&#125; 如以上示例，并行处理每行矩阵元素，待所有行处理结束再对每行处理结果进行合并。 内部变量// 可重入锁控制对barrier的访问private final ReentrantLock lock = new ReentrantLock();// 控制线程阻塞，直到所有线程”到达”private final Condition trip = lock.newCondition();// 多少个参与方(线程)private final int parties;// 到达栅栏后执行的线程private final Runnable barrierCommand;// 内部类表示目前是哪一代private Generation generation = new Generation()// 还有几个参与方(线程)在未到达private int count; Generation为内部类，当触发栅栏或者重置，generation就会改变。 1234private static class Generation &#123; // 标识栅栏有没有被"踢翻" boolean broken = false;&#125; CyclicBarrier.await由源码中的示例代码，await是CyclicBarrier的主要起作用的方法。首先先看一下构造方法中对内部变量的初始化： 1234567public CyclicBarrier(int parties, Runnable barrierAction) &#123; if (parties &lt;= 0) throw new IllegalArgumentException(); this.parties = parties; // 初始parties个线程 this.count = parties; this.barrierCommand = barrierAction; &#125; 构造方法里就初始化了三个变量，分别是表示多少个线程的parties、还有多少个线程未到达的count、后置线程barrierCommand。await方法是调用内部私有方法dowait: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; final ReentrantLock lock = this.lock; // 加锁 lock.lock(); try &#123; // 当前代 final Generation g = generation; if (g.broken) // 抱歉，栅栏已经被踢翻了 throw new BrokenBarrierException(); if (Thread.interrupted()) &#123; // 线程中断了，需要唤醒所有线程 breakBarrier(); throw new InterruptedException(); &#125; int index = --count; if (index == 0) &#123; // tripped // 所有线程已到达 boolean ranAction = false; try &#123; final Runnable command = barrierCommand; if (command != null) // 后置线程 command.run(); ranAction = true; // 重置状态并唤醒所有线程 nextGeneration(); return 0; &#125; finally &#123; if (!ranAction) breakBarrier(); &#125; &#125; // loop until tripped, broken, interrupted, or timed out for (;;) &#123; try &#123; if (!timed) // condition.await 调用AQS里的Condition实现类 trip.await(); else if (nanos &gt; 0L) // 允许只等待一定时间 nanos = trip.awaitNanos(nanos); &#125; catch (InterruptedException ie) &#123; if (g == generation &amp;&amp; ! g.broken) &#123; breakBarrier(); throw ie; &#125; else &#123; // We're about to finish waiting even if we had not // been interrupted, so this interrupt is deemed to // "belong" to subsequent execution. Thread.currentThread().interrupt(); &#125; &#125; if (g.broken) throw new BrokenBarrierException(); if (g != generation) // 物是人非，已经不是睡之前的时代了 return index; if (timed &amp;&amp; nanos &lt;= 0L) &#123; breakBarrier(); throw new TimeoutException(); &#125; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125; CyclicBarrier利用ReentrantLock控制对barrier的加锁访问，ReentrantLock.condition控制线程的阻塞唤醒。内部类Generation表示栅栏的一次生命周期，而每次栅栏被踢翻，generation要换代，即CyclicBarrier是可循环复用的。]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>JDK</tag>
        <tag>源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK源码阅读之CountDownLatch]]></title>
    <url>%2Fbdd3aaa7.html</url>
    <content type="text"><![CDATA[写在前面作者Doug Lea如此描述这个类：A synchronization aid that allows one or more threads to wait until a set of operations being performed in other threads completes.这是一个多线程协调的辅助类。源码中给出的示例代码： 1234567891011121314151617181920212223242526272829303132class Driver &#123; // ... void main() throws InterruptedException &#123; CountDownLatch startSignal = new CountDownLatch(1); CountDownLatch doneSignal = new CountDownLatch(N); for (int i = 0; i &lt; N; ++i) // create and start threads new Thread(new Worker(startSignal, doneSignal)).start(); doSomethingElse(); // don't let run yet startSignal.countDown(); // let all threads proceed doSomethingElse(); doneSignal.await(); // wait for all to finish &#125;&#125;class Worker implements Runnable &#123; private final CountDownLatch startSignal; private final CountDownLatch doneSignal; Worker(CountDownLatch startSignal, CountDownLatch doneSignal) &#123; this.startSignal = startSignal; this.doneSignal = doneSignal; &#125; public void run() &#123; try &#123; startSignal.await(); doWork(); doneSignal.countDown(); &#125; catch (InterruptedException ex) &#123;&#125; // return; &#125; void doWork() &#123; ... &#125;&#125;&#125; 通过示例对CountDownLatch的使用场景应该有个清晰的认识。即当有需要线程等待，直到在其他线程的一系列操作完成之后，再接着往下执行。 Sync变量Sync类是CountDownLatch的一个内部类，继承自AbstractQueuedSynchronizer，也就是常说的AQS。内部类重写了AQS的tryAcquireShared和tryReleaseShared两个方法。此外Sync的构造函数带一个int参数，在构造函数内调用了AQS的setState方法，这个方法是对AQS的内部一个int volatile变量赋值。 1234567891011121314151617181920212223242526private static final class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 4982264981922014374L; Sync(int count) &#123; setState(count); &#125; int getCount() &#123; return getState(); &#125; protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1; &#125; protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125; &#125; 在上边的示例中，我们用到了CountDownLatch的await方法和countDown方法，CountDownLatch的功能也就是通过这两个方法实现。这两个方法其实也就是调用sync。 CountDownLatch.await功能：当前线程等待，直到state等于0，或该线程interrupt。该方法就是调用sync.acquireSharedInterruptibly(1)。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 调用实现类Sync的tryAcquireShared if (tryAcquireShared(arg) &lt; 0) // state 不等于 0 则执行 doAcquireSharedInterruptibly(arg);&#125;private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; // 用一个链表来表示需要"wait"的线程，在链表尾部加入一个node // 注意 如果head == null ,则初始化一个head，令head.next = node // 所以能理解state==0,一一唤醒所有等待的线程时，是唤醒头结点的下一节点所表示的线程 // 这样就达到了唤醒所有线程的目的 final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; // 前驱 final Node p = node.predecessor(); // 如果当前节点为头节点 if (p == head) &#123; // 调用CountDownLatch实现类里的tryAcquireShared int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; // 当state == 0时，设置node为头结点 // 并且唤醒(LockSupport.unpark)node下一节点的所表示的线程 setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; // wait，直到state == 0 时被唤醒（LockSupport.unpark） if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; 总结：CountDownLatch.await就是调用LockSupport.park阻塞当前线程，并用一链表表示所有阻塞的线程，方便唤醒时一一唤醒。 CountDownLatch.countDown功能：令state减1，但state为0时，唤醒所有等待线程。该方法是调用sync.releaseShared(1)。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677 public final boolean releaseShared(int arg) &#123; // 调用实现类Sync的tryReleaseShared // state减1 if (tryReleaseShared(arg)) &#123; // 当state减为0时 doReleaseShared(); return true; &#125; return false; &#125;// 唤醒等待链表的头结点的下一节点// 下一节点唤醒后在doAcquireSharedInterruptibly这个方法中继续循环// 直到执行setHeadAndPropagate，在此方法中又会调用doReleaseShared,唤醒接下来的节点// 依次一一唤醒，直到唤醒所有等待线程节点 private void doReleaseShared() &#123; /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. */ for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; // cas头结点状态为初始状态 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases // 此方法中是唤醒头结点的下一线程节点 unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; // 如果线程节点改变重新循环 if (h == head) // loop if head changed break; &#125; &#125;// 唤醒node下一线程节点 private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; // node后继节点可能为null或cancel for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) // 唤醒节点s表示线程 LockSupport.unpark(s.thread); &#125; CountDownLatch源码分析的整个流程就是这样。CountDownLatch的功能是基于AQS展开，在后续的JUC的分析文章中还可以看到AQS的身影。接下来仍会对JDK中的源码做一些分析工作，重心会在JUC上。谢谢。]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>JDK</tag>
        <tag>源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QMQ源码分析之Actor]]></title>
    <url>%2F93d6d117.html</url>
    <content type="text"><![CDATA[前言 QMQ有关actor的一篇文章阐述了actor的应用场景。即client消费消息的请求会先进入一个RequestQueue，在client消费消息时，往往存在多个主题、多个消费组共享一个RequestQueue消费消息。在这个Queue中，存在不同主题的有不同消费组数量，以及不同消费组有不同consumer数量，那么就会存在抢占资源的情况。举个文章中的例子，一个主题下有两个消费组A和B，A有100个consumer，B有200个consumer，那么在RequestQueue中来自B的请求可能会多于A，这个时候就存在消费unfair的情况，所以需要隔离不同主题不同消费组以保证fair。除此之外，当consumer消费能力不足，造成broker消息堆积，这个时候就会导致consumer所在消费组总在消费”老消息”，影响全局整体的一个消费能力。因为”老消息”不会存在page cache中，这个时候很可能就会从磁盘load，那么表现是RequestQueue中来自消费”老消息”消费组的请求处理时间过长，影响到其他主题消费组的消费，因此这个时候也需要做策略来避免不同消费组的相互影响。所以QMQ就有了actor机制，以消除各个消费组之间因消费能力不同、consumer数量不同而造成的相互影响各自的消费能力。 PullMessageWorker要了解QMQ的actor模式是如何起作用的，就要先来看看Broker是如何处理消息拉取请求的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293class PullMessageWorker implements ActorSystem.Processor&lt;PullMessageProcessor.PullEntry&gt; &#123; // 消息存储层 private final MessageStoreWrapper store; // actor private final ActorSystem actorSystem; private final ConcurrentMap&lt;String, ConcurrentMap&lt;String, Object&gt;&gt; subscribers; PullMessageWorker(MessageStoreWrapper store, ActorSystem actorSystem) &#123; this.store = store; this.actorSystem = actorSystem; this.subscribers = new ConcurrentHashMap&lt;&gt;(); &#125; void pull(PullMessageProcessor.PullEntry pullEntry) &#123; // subject+group作actor调度粒度 final String actorPath = ConsumerGroupUtils.buildConsumerGroupKey(pullEntry.subject, pullEntry.group); // actor调度 actorSystem.dispatch(actorPath, pullEntry, this); &#125; @Override public boolean process(PullMessageProcessor.PullEntry entry , ActorSystem.Actor&lt;PullMessageProcessor.PullEntry&gt; self) &#123; QMon.pullQueueTime(entry.subject, entry.group, entry.pullBegin); //开始处理请求的时候就过期了，那么就直接不处理了，也不返回任何东西给客户端，客户端等待超时 //因为出现这种情况一般是server端排队严重，暂时挂起客户端可以避免情况恶化 // deadline机制，如果QMQ认为这个消费请求来不及处理，那么就直接返回，避免雪崩 if (entry.expired()) &#123; QMon.pullExpiredCountInc(entry.subject, entry.group); return true; &#125; if (entry.isInValid()) &#123; QMon.pullInValidCountInc(entry.subject, entry.group); return true; &#125; // 存储层find消息 final PullMessageResult pullMessageResult = store.findMessages(entry.pullRequest); if (pullMessageResult == PullMessageResult.FILTER_EMPTY || pullMessageResult.getMessageNum() &gt; 0 || entry.isPullOnce() || entry.isTimeout()) &#123; entry.processMessageResult(pullMessageResult); return true; &#125; // 没有拉取到消息，那么挂起该actor self.suspend(); // timer task，在超时前唤醒actor if (entry.setTimerOnDemand()) &#123; QMon.suspendRequestCountInc(entry.subject, entry.group); // 订阅消息，一有消息来就唤醒该actor subscribe(entry.subject, entry.group); return false; &#125; // 已经超时，那么即刻唤醒调度 self.resume(); entry.processNoMessageResult(); return true; &#125; // 订阅 private void subscribe(String subject, String group) &#123; ConcurrentMap&lt;String, Object&gt; map = subscribers.get(subject); if (map == null) &#123; map = new ConcurrentHashMap&lt;&gt;(); map = ObjectUtils.defaultIfNull(subscribers.putIfAbsent(subject, map), map); &#125; map.putIfAbsent(group, HOLDER); &#125; // 有消息来就唤醒订阅的subscriber void remindNewMessages(final String subject) &#123; final ConcurrentMap&lt;String, Object&gt; map = this.subscribers.get(subject); if (map == null) return; for (String group : map.keySet()) &#123; map.remove(group); this.actorSystem.resume(ConsumerGroupUtils.buildConsumerGroupKey(subject, group)); QMon.resumeActorCountInc(subject, group); &#125; &#125;&#125;// ActorSystem内定义的处理接口public interface ActorSystem.Processor&lt;T&gt; &#123; boolean process(T message, Actor&lt;T&gt; self);&#125; 能看除在这里起作用的是这个actorSystem。PullMessageWorker继承了ActorSystem.Processor，所以真正处理拉取请求的是这个接口里的process方法。请求到达pullMessageWorker，worker将该次请求交给actorSystem调度，调度到这次请求时，worker还有个根据拉取结果做反应的策略，即如果暂时没有消息，那么suspend，以一个timer task定时resume；如果在timer task执行之前有消息进来，那么也会即时resume。 ActorSystem接下来就看看ActorSystem里边是如何做的公平调度。 123456789101112131415161718192021222324public class ActorSystem &#123; // 内部维护的是一个ConcurrentMap，key即PullMessageWorker里的subject+group private final ConcurrentMap&lt;String, Actor&gt; actors; // 执行actor的executor private final ThreadPoolExecutor executor; private final AtomicInteger actorsCount; private final String name; public ActorSystem(String name) &#123; this(name, Runtime.getRuntime().availableProcessors() * 4, true); &#125; public ActorSystem(String name, int threads, boolean fair) &#123; this.name = name; this.actorsCount = new AtomicInteger(); // 这里根据fair参数初始化一个优先级队列作为executor的参数，处理关于前言里说的"老消息"的情况 BlockingQueue&lt;Runnable&gt; queue = fair ? new PriorityBlockingQueue&lt;&gt;() : new LinkedBlockingQueue&lt;&gt;(); this.executor = new ThreadPoolExecutor(threads, threads, 60, TimeUnit.MINUTES, queue, new NamedThreadFactory("actor-sys-" + name)); this.actors = Maps.newConcurrentMap(); QMon.dispatchersGauge(name, actorsCount::doubleValue); QMon.actorSystemQueueGauge(name, () -&gt; (double) executor.getQueue().size()); &#125;&#125; 可以看到，用一个线程池处理actor的调度执行，这个线程池里的队列是一个优先级队列。优先级队列存储的元素是Actor。关于Actor我们稍后来看，先来看一下ActorSystem的处理调度流程。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// PullMessageWorker调用的就是这个方法 public &lt;E&gt; void dispatch(String actorPath, E msg, Processor&lt;E&gt; processor) &#123; // 取得actor Actor&lt;E&gt; actor = createOrGet(actorPath, processor); // 在后文Actor定义里能看到，actor内部维护一个queue，这里actor仅仅是offer(msg) actor.dispatch(msg); // 执行调度 schedule(actor, true); &#125;// 无消息时，则会挂起 public void suspend(String actorPath) &#123; Actor actor = actors.get(actorPath); if (actor == null) return; actor.suspend(); &#125;// 有消息则恢复，可以理解成线程的"就绪状态" public void resume(String actorPath) &#123; Actor actor = actors.get(actorPath); if (actor == null) return; actor.resume(); // 立即调度，可以留意一下那个false // 当actor是"可调度状态"时，这个actor是否能调度是取决于actor的queue是否有消息 schedule(actor, false); &#125; private &lt;E&gt; Actor&lt;E&gt; createOrGet(String actorPath, Processor&lt;E&gt; processor) &#123; Actor&lt;E&gt; actor = actors.get(actorPath); if (actor != null) return actor; Actor&lt;E&gt; add = new Actor&lt;&gt;(this.name, actorPath, this, processor, DEFAULT_QUEUE_SIZE); Actor&lt;E&gt; old = actors.putIfAbsent(actorPath, add); if (old == null) &#123; LOG.info("create actorSystem: &#123;&#125;", actorPath); actorsCount.incrementAndGet(); return add; &#125; return old; &#125;// 将actor入队的地方 private &lt;E&gt; boolean schedule(Actor&lt;E&gt; actor, boolean hasMessageHint) &#123; // 如果actor不能调度，则ret false if (!actor.canBeSchedule(hasMessageHint)) return false; // 设置actor为"可调度状态" if (actor.setAsScheduled()) &#123; // 提交时间，和actor执行总耗时共同决定在队列里的优先级 actor.submitTs = System.currentTimeMillis(); // 入队，入的是线程池里的优先级队列 this.executor.execute(actor); return true; &#125; // actor.setAsScheduled()里，这里是actor已经是可调度状态，那么没必要再次入队 return false; &#125; actorSystem维护一个线程池，线程池队列具有优先级，队列存储元素是actor。actor的粒度是subject+group。Actor是一个Runnable，且因为是优先级队列的存储元素所以需继承Comparable接口（队列并没有传Comparator参数），并且actor有四种状态，初始状态、可调度状态、挂起状态、调度状态（这个状态其实不存在，但是暂且这么叫以帮助理解）。接下来看看Actor这个类：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175public static class Actor&lt;E&gt; implements Runnable, Comparable&lt;Actor&gt; &#123; // 初始状态 private static final int Open = 0; // 可调度状态 private static final int Scheduled = 2; // 掩码，二进制表示:11 与Open和Scheduled作&amp;运算 // shouldScheduleMask&amp;currentStatus != Open 则为不可置为调度状态（当currentStatus为挂起状态或调度状态） private static final int shouldScheduleMask = 3; private static final int shouldNotProcessMask = ~2; // 挂起状态 private static final int suspendUnit = 4; //每个actor至少执行的时间片 private static final int QUOTA = 5; // status属性内存偏移量，用Unsafe操作 private static long statusOffset; static &#123; try &#123; statusOffset = Unsafe.instance.objectFieldOffset(Actor.class.getDeclaredField("status")); &#125; catch (Throwable t) &#123; throw new ExceptionInInitializerError(t); &#125; &#125; final String systemName; final ActorSystem actorSystem; // actor内部维护的queue，后文简单分析下 final BoundedNodeQueue&lt;E&gt; queue; // ActorSystem内部定义接口，PullMessageWorker实现的就是这个接口，用于真正业务逻辑处理的地方 final Processor&lt;E&gt; processor; private final String name; // 一个actor执行总耗时 private long total; // actor执行提交时间，即actor入队时间 private volatile long submitTs; //通过Unsafe操作 private volatile int status; Actor(String systemName, String name, ActorSystem actorSystem, Processor&lt;E&gt; processor, final int queueSize) &#123; this.systemName = systemName; this.name = name; this.actorSystem = actorSystem; this.processor = processor; this.queue = new BoundedNodeQueue&lt;&gt;(queueSize); QMon.actorQueueGauge(systemName, name, () -&gt; (double) queue.count()); &#125; // 入队，是actor内部的队列 boolean dispatch(E message) &#123; return queue.add(message); &#125; // actor执行的地方 @Override public void run() &#123; long start = System.currentTimeMillis(); String old = Thread.currentThread().getName(); try &#123; Thread.currentThread().setName(systemName + "-" + name); if (shouldProcessMessage()) &#123; processMessages(); &#125; &#125; finally &#123; long duration = System.currentTimeMillis() - start; // 每次actor执行的耗时累加到total total += duration; QMon.actorProcessTime(name, duration); Thread.currentThread().setName(old); // 设置为"空闲状态"，即初始状态 (currentStatus &amp; ~Scheduled) setAsIdle(); // 进行下一次调度 this.actorSystem.schedule(this, false); &#125; &#125; void processMessages() &#123; long deadline = System.currentTimeMillis() + QUOTA; while (true) &#123; E message = queue.peek(); if (message == null) return; // 处理业务逻辑 boolean process = processor.process(message, this); // 失败，该message不会出队，等待下一次调度 // 如pullMessageWorker中没有消息时将actor挂起 if (!process) return; // 出队 queue.pollNode(); // 每个actor只有QUOTA个时间片的执行时间 if (System.currentTimeMillis() &gt;= deadline) return; &#125; &#125; final boolean shouldProcessMessage() &#123; // 能够真正执行业务逻辑的判断 // 一种场景是，针对挂起状态，由于没有拉取到消息该actor置为挂起状态 // 自然就没有抢占时间片的必要了 return (currentStatus() &amp; shouldNotProcessMask) == 0; &#125; // 能否调度 private boolean canBeSchedule(boolean hasMessageHint) &#123; int s = currentStatus(); if (s == Open || s == Scheduled) return hasMessageHint || !queue.isEmpty(); return false; &#125; public final boolean resume() &#123; while (true) &#123; int s = currentStatus(); int next = s &lt; suspendUnit ? s : s - suspendUnit; if (updateStatus(s, next)) return next &lt; suspendUnit; &#125; &#125; public final void suspend() &#123; while (true) &#123; int s = currentStatus(); if (updateStatus(s, s + suspendUnit)) return; &#125; &#125; final boolean setAsScheduled() &#123; while (true) &#123; int s = currentStatus(); // currentStatus为非Open状态，则ret false if ((s &amp; shouldScheduleMask) != Open) return false; // 更新actor状态为调度状态 if (updateStatus(s, s | Scheduled)) return true; &#125; &#125; final void setAsIdle() &#123; while (true) &#123; int s = currentStatus(); // 更新actor状态位不可调度状态，(这里可以理解为更新为初始状态Open) if (updateStatus(s, s &amp; ~Scheduled)) return; &#125; &#125; final int currentStatus() &#123; // 根据status在内存中的偏移量取得status return Unsafe.instance.getIntVolatile(this, statusOffset); &#125; private boolean updateStatus(int oldStatus, int newStatus) &#123; // Unsafe 原子操作，处理status的轮转变更 return Unsafe.instance.compareAndSwapInt(this, statusOffset, oldStatus, newStatus); &#125; // 决定actor在优先级队列里的优先级的地方 // 先看总耗时，以达到动态限速，保证执行"慢"的请求（已经堆积的消息拉取请求）在后执行 // 其次看提交时间，先提交的actor先执行 @Override public int compareTo(Actor o) &#123; int result = Long.compare(total, o.total); return result == 0 ? Long.compare(submitTs, o.submitTs) : result; &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Actor&lt;?&gt; actor = (Actor&lt;?&gt;) o; return Objects.equals(systemName, actor.systemName) &amp;&amp; Objects.equals(name, actor.name); &#125; @Override public int hashCode() &#123; return Objects.hash(systemName, name); &#125;&#125; Actor实现了Comparable，在优先级队列里优先级是Actor里的total和submitTs共同决定的。total是actor执行总耗时，submitTs是调度时间。那么对于处理较慢的actor自然就会在队列里相对”尾部”位置，这时就做到了根据actor的执行耗时的一个动态限速。Actor利用Unsafe机制来控制各个状态的轮转原子性更新的，且每个actor执行时间可以简单理解为5个时间片（暂且这么理解，其实并不是时间片）。其实工作进行到这里就可以结束了，但是抱着对于编程的热爱（周末闲的慌），还可以往下接着看看。Actor内部维护一个Queue，这个Queue是自定义的，是一个Lock-free bounded non-blocking multiple-producer single-consumer queue。JDK里的QUEUE多数都是用锁控制，不用锁，猜测也应该是用Unsafe 原子操作实现。那么来看看吧： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176private static class BoundedNodeQueue&lt;T&gt; &#123;// 头结点、尾节点在内存中的偏移量 private final static long enqOffset, deqOffset; static &#123; try &#123; enqOffset = Unsafe.instance.objectFieldOffset(BoundedNodeQueue.class.getDeclaredField("_enqDoNotCallMeDirectly")); deqOffset = Unsafe.instance.objectFieldOffset(BoundedNodeQueue.class.getDeclaredField("_deqDoNotCallMeDirectly")); &#125; catch (Throwable t) &#123; throw new ExceptionInInitializerError(t); &#125; &#125; private final int capacity; // 尾节点，通过enqOffset操作 private volatile Node&lt;T&gt; _enqDoNotCallMeDirectly; // 头结点，通过deqOffset操作 private volatile Node&lt;T&gt; _deqDoNotCallMeDirectly; protected BoundedNodeQueue(final int capacity) &#123; if (capacity &lt; 0) throw new IllegalArgumentException("AbstractBoundedNodeQueue.capacity must be &gt;= 0"); this.capacity = capacity; final Node&lt;T&gt; n = new Node&lt;T&gt;(); setDeq(n); setEnq(n); &#125;// 获取尾节点 private Node&lt;T&gt; getEnq() &#123; // getObjectVolatile这种方式保证拿到的都是最新数据 return (Node&lt;T&gt;) Unsafe.instance.getObjectVolatile(this, enqOffset); &#125;// 设置尾节点，仅在初始化时用 private void setEnq(Node&lt;T&gt; n) &#123; Unsafe.instance.putObjectVolatile(this, enqOffset, n); &#125; private boolean casEnq(Node&lt;T&gt; old, Node&lt;T&gt; nju) &#123; // cas，循环设置，直到成功 return Unsafe.instance.compareAndSwapObject(this, enqOffset, old, nju); &#125;// 获取头结点 private Node&lt;T&gt; getDeq() &#123; return (Node&lt;T&gt;) Unsafe.instance.getObjectVolatile(this, deqOffset); &#125;// 仅在初始化时用 private void setDeq(Node&lt;T&gt; n) &#123; Unsafe.instance.putObjectVolatile(this, deqOffset, n); &#125;// cas设置头结点 private boolean casDeq(Node&lt;T&gt; old, Node&lt;T&gt; nju) &#123; return Unsafe.instance.compareAndSwapObject(this, deqOffset, old, nju); &#125;// 与其叫count，不如唤作index，但是是否应该考虑溢出的情况？ public final int count() &#123; final Node&lt;T&gt; lastNode = getEnq(); final int lastNodeCount = lastNode.count; return lastNodeCount - getDeq().count; &#125; /** * @return the maximum capacity of this queue */ public final int capacity() &#123; return capacity; &#125; public final boolean add(final T value) &#123; for (Node&lt;T&gt; n = null; ; ) &#123; final Node&lt;T&gt; lastNode = getEnq(); final int lastNodeCount = lastNode.count; if (lastNodeCount - getDeq().count &lt; capacity) &#123; // Trade a branch for avoiding to create a new node if full, // and to avoid creating multiple nodes on write conflict á la Be Kind to Your GC if (n == null) &#123; n = new Node&lt;T&gt;(); n.value = value; &#125; n.count = lastNodeCount + 1; // Piggyback on the HB-edge between getEnq() and casEnq() // Try to putPullLogs the node to the end, if we fail we continue loopin' // 相当于 // enq -&gt; next = new Node(value); enq = neq -&gt; next; if (casEnq(lastNode, n)) &#123; // 注意一下这个Node.setNext方法 lastNode.setNext(n); return true; &#125; &#125; else return false; // Over capacity—couldn't add the node &#125; &#125; public final boolean isEmpty() &#123; // enq == deq 即为empty return getEnq() == getDeq(); &#125; /** * Removes the first element of this queue if any * * @return the value of the first element of the queue, null if empty */ public final T poll() &#123; final Node&lt;T&gt; n = pollNode(); return (n != null) ? n.value : null; &#125; public final T peek() &#123; Node&lt;T&gt; n = peekNode(); return (n != null) ? n.value : null; &#125; protected final Node&lt;T&gt; peekNode() &#123; for (; ; ) &#123; final Node&lt;T&gt; deq = getDeq(); final Node&lt;T&gt; next = deq.next(); if (next != null || getEnq() == deq) return next; &#125; &#125; /** * Removes the first element of this queue if any * * @return the `Node` of the first element of the queue, null if empty */ public final Node&lt;T&gt; pollNode() &#123; for (; ; ) &#123; final Node&lt;T&gt; deq = getDeq(); final Node&lt;T&gt; next = deq.next(); if (next != null) &#123; if (casDeq(deq, next)) &#123; deq.value = next.value; deq.setNext(null); next.value = null; return deq; &#125; // else we retry (concurrent consumers) // 比较套路的cas操作，就不多说了 &#125; else if (getEnq() == deq) return null; // If we got a null and head meets tail, we are empty &#125; &#125; public static class Node&lt;T&gt; &#123; private final static long nextOffset; static &#123; try &#123; nextOffset = Unsafe.instance.objectFieldOffset(Node.class.getDeclaredField("_nextDoNotCallMeDirectly")); &#125; catch (Throwable t) &#123; throw new ExceptionInInitializerError(t); &#125; &#125; protected T value; protected int count; // 也是利用偏移量操作 private volatile Node&lt;T&gt; _nextDoNotCallMeDirectly; public final Node&lt;T&gt; next() &#123; return (Node&lt;T&gt;) Unsafe.instance.getObjectVolatile(this, nextOffset); &#125; protected final void setNext(final Node&lt;T&gt; newNext) &#123; // 这里有点讲究，下面分析下 Unsafe.instance.putOrderedObject(this, nextOffset, newNext); &#125; &#125;&#125; 如上代码，是通过属性在内存的偏移量，结合cas原子操作来进行更新赋值等操作，以此来实现lock-free，这是比较常规的套路。值得一说的是Node里的setNext方法，这个方法的调用是在cas节点后，对”上一位置”的next节点进行赋值。而这个方法使用的是Unsafe.instance.putOrderedObject，要说这个putOrderedObject，就不得不说MESI，缓存一致性协议。如volatile，当进行写操作时，它是依靠storeload barrier来实现其他线程对此的可见性。而putOrderedObject也是依靠内存屏障，只不过是storestore barrier。storestore是比storeload快速的一种内存屏障。在硬件层面，内存屏障分两种：Load-Barrier和Store-Barrier。Load-Barrier是让高速缓存中的数据失效，强制重新从主内存加载数据；Store-Barrier是让写入高速缓存的数据更新写入主内存，对其他线程可见。而java层面的四种内存屏障无非是硬件层面的两种内存屏障的组合而已。那么可见，storestore barrier自然比storeload barrier快速。那么有一个问题，我们可不可以在这里也用cas操作呢？答案是可以，但没必要。你可以想想这里为什么没必要。谢谢。]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QMQ源码分析之发送消息]]></title>
    <url>%2Ff0aaa51f.html</url>
    <content type="text"><![CDATA[前言 QMQ发送消息部分的源码从两端来分析，即client端和broker端。 client从官方的producer文档能很容易的找到入口就是MessageProducerProvider这个类。通过这个文档，能发现这个类有两个属性是需要我们设置的，即appCode、metaServer。这里的appCode用来标识应用，metaServer是meta server地址，在发送消息时，可以通过这个地址获取broker cluser。从入口MessageProducerProvider看看： 123456789// 生产消息 @Override public Message generateMessage(String subject) &#123; BaseMessage msg = new BaseMessage(idGenerator.getNext(), subject); msg.setExpiredDelay(configs.getMinExpiredTime(), TimeUnit.MINUTES); msg.setProperty(BaseMessage.keys.qmq_appCode, appCode); return msg; &#125; 从以上初始化一条消息的代码能看到，QMQ自身会设置一个过期时间，一个appCode的属性。而这里我最关心的是，它的id的是怎么组织的。 1234567891011121314151617181920212223242526public class TimestampAndHostIdGenerator implements IdGenerator &#123; private static final int[] codex = &#123;2, 3, 5, 6, 8, 9, 19, 11, 12, 14, 15, 17, 18&#125;; private static final AtomicInteger messageOrder = new AtomicInteger(0); private static final String localAddress = NetworkUtils.getLocalAddress(); //在生成message id的时候带上进程id，避免一台机器上部署多个服务都发同样的消息时出问题 private static final int PID = PidUtil.getPid(); @Override public String getNext() &#123; StringBuilder sb = new StringBuilder(40); long time = System.currentTimeMillis(); String ts = new Timestamp(time).toString(); for (int idx : codex) // 处理时间 sb.append(ts.charAt(idx)); // 本机地址 sb.append('.').append(localAddress); // pid sb.append('.').append(PID); sb.append('.').append(messageOrder.getAndIncrement()); //可能为负数.但是无所谓. return sb.toString(); &#125;&#125; QMQ的msgId是以时间+ip+pid+seq组织的。消息初始化了，那么就是发送了。 12345678910111213141516171819202122232425262728293031@Overridepublic void sendMessage(Message message, MessageSendStateListener listener) &#123; if (!STARTED.get()) &#123; throw new RuntimeException("MessageProducerProvider未初始化，如果使用非Spring的方式请确认init()是否调用"); &#125; // trace信息 try (Scope ignored = tracer.buildSpan("Qmq.Produce.Send") .withTag("appCode", appCode) .withTag("subject", message.getSubject()) .withTag("messageId", message.getMessageId()) .startActive(true)) &#123; if (messageTracker == null) &#123; message.setDurable(false); &#125; // 消息被包装在ProduceMessageImpl里 ProduceMessageImpl pm = initProduceMessage(message, listener); // 非持久消息那么直接发送 if (!message.isDurable()) &#123; pm.send(); return; &#125; // 事务消息 if (!messageTracker.trackInTransaction(pm)) &#123; // false则直接发送 pm.send(); &#125; &#125;&#125; QMQ是支持事务消息的，先来看下事务消息，trackInTransaction这个方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263 public boolean trackInTransaction(ProduceMessage message) &#123; MessageStore messageStore = this.transactionProvider.messageStore(); message.setStore(messageStore); // 处在事务中 if (transactionProvider.isInTransaction()) &#123; // 开始事务 this.transactionListener.beginTransaction(messageStore); this.transactionProvider.setTransactionListener(transactionListener); messageStore.beginTransaction(); this.transactionListener.addMessage(message); return true; &#125; else &#123; try &#123; message.save(); &#125; catch (Exception e) &#123; message.getBase().setStoreAtFailed(true); &#125; return false; &#125; &#125; // transactionProvider isInTransaction @Override public boolean isInTransaction() &#123; return TransactionSynchronizationManager.isActualTransactionActive(); &#125; // transactionListener beginTransaction public void beginTransaction(MessageStore store) &#123; // 此处的holder申明为 // private ThreadLocal&lt;TransactionMessageHolder&gt; holder = new ThreadLocal&lt;&gt;(); TransactionMessageHolder current = holder.get(); if (current == null) &#123; holder.set(new TransactionMessageHolder(store)); &#125; &#125;// TransactionMessageHolderclass TransactionMessageHolder &#123; public void insertMessage(ProduceMessage message) &#123; add(message); &#125; List&lt;ProduceMessage&gt; get() &#123; return queue; &#125; private final MessageStore store; private List&lt;ProduceMessage&gt; queue = Collections.emptyList(); TransactionMessageHolder(MessageStore store) &#123; this.store = store; &#125; private void add(ProduceMessage message) &#123; if (queue.isEmpty()) queue = new ArrayList&lt;&gt;(1); queue.add(message); message.setStore(store); &#125;&#125; QMQ的事务消息是利用与业务DB共享连接，所以能够将QMQ事务和业务事务相绑定。当发送QMQ消息时，要是业务逻辑正在一个事务中，那么QMQ会将消息暂存到ThreadLocal中，当业务事务提交时，再将消息从ThreadLocal中取出，进行发送逻辑。 12345678910111213141516171819202122@Overridepublic void afterCommit() &#123; List&lt;ProduceMessage&gt; list = remove(); for (int i = 0; i &lt; list.size(); ++i) &#123; ProduceMessage msg = list.get(i); try &#123; msg.send(); &#125; catch (Throwable t) &#123; logger.error("消息发送失败&#123;&#125;", msg.getMessageId(), t); &#125; &#125;&#125;@Overridepublic void afterCompletion() &#123; List&lt;ProduceMessage&gt; list = remove(); for (int i = 0; i &lt; list.size(); ++i) &#123; ProduceMessage msg = list.get(i); logger.info("事务提交失败, 消息(&#123;&#125;)被忽略.subject:&#123;&#125;", msg.getMessageId(), msg.getSubject()); &#125;&#125; QMQ的事务消息的大概流程就是这样，接着来看一下具体发送的逻辑： 1234567891011121314151617181920212223242526272829if (state.compareAndSet(INIT, QUEUED)) &#123; tries.incrementAndGet(); if (sendSync()) return; try (Scope scope = tracer.buildSpan("Qmq.QueueSender.Send").startActive(false)) &#123; traceSpan = scope.span(); if (sender.offer(this)) &#123; LOGGER.info("进入发送队列 &#123;&#125;:&#123;&#125;", getSubject(), getMessageId()); &#125; else if (store != null) &#123; enterQueueFail.inc(); LOGGER.info("内存发送队列已满! 此消息将暂时丢弃,等待补偿服务处理 &#123;&#125;:&#123;&#125;", getSubject(), getMessageId()); failed(); &#125; else &#123; LOGGER.info("内存发送队列已满! 此消息在用户进程阻塞,等待队列激活 &#123;&#125;:&#123;&#125;", getSubject(), getMessageId()); if (sender.offer(this, 50)) &#123; LOGGER.info("进入发送队列 &#123;&#125;:&#123;&#125;", getSubject(), getMessageId()); &#125; else &#123; enterQueueFail.inc(); LOGGER.info("由于无法入队,发送失败！取消发送 &#123;&#125;:&#123;&#125;", getSubject(), getMessageId()); onFailed(); &#125; &#125; &#125; &#125; else &#123; enterQueueFail.inc(); throw new IllegalStateException("同一条消息不能被入队两次."); &#125; 发送QMQ消息时，会将消息入队，发送时会批量发送。而消息要是失败，同时消息也是事务消息，那么会有补偿任务来补发消息。QMQ用相对简单的方式解决了分布式事务消息问题，还是比较巧妙的。 12345678910111213141516171819202122232425262728293031@Overridepublic Map&lt;String, MessageException&gt; send(List&lt;ProduceMessage&gt; messages) throws ClientSendException, RemoteException, BrokerRejectException &#123; sendMessageCountMetrics.inc(messages.size()); long start = System.currentTimeMillis(); try &#123; // 异步获取broker cluser BrokerClusterInfo cluster = brokerService.getClusterBySubject(clientType, subject); // 负载均衡，random BrokerGroupInfo target = brokerLoadBalance.loadBalance(cluster, lastSentBroker); if (target == null) &#123; throw new ClientSendException(ClientSendException.SendErrorCode.CREATE_CHANNEL_FAIL); &#125; lastSentBroker = target; // 这里会有失败熔断等处理 Datagram response = doSend(target, messages); RemotingHeader responseHeader = response.getHeader(); int code = responseHeader.getCode(); switch (code) &#123; case CommandCode.SUCCESS: return process(target, response); case CommandCode.BROKER_REJECT: handleSendReject(target); throw new BrokerRejectException(""); default: throw new RemoteException(); &#125; &#125; finally &#123; sendMessageTimerMetrics.update(System.currentTimeMillis() - start, TimeUnit.MILLISECONDS); &#125;&#125; 发送消息的client部分就先说到这里。 brokerbroker接收到消息之后，会将消息append到message_log中，这里是顺序写。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384@Overridepublic CompletableFuture&lt;Datagram&gt; processRequest(ChannelHandlerContext ctx, RemotingCommand command) &#123; List&lt;RawMessage&gt; messages; try &#123; // 反序列化，但并不是反序列化整个消息体，payload messages = deserializeRawMessages(command); &#125; catch (Exception e) &#123; LOG.error(&quot;received invalid message. channel: &#123;&#125;&quot;, ctx.channel(), e); QMon.brokerReceivedInvalidMessageCountInc(); final Datagram response = RemotingBuilder.buildEmptyResponseDatagram(CommandCode.BROKER_ERROR, command.getHeader()); return CompletableFuture.completedFuture(response); &#125; BrokerStats.getInstance().getLastMinuteSendRequestCount().add(messages.size()); final ListenableFuture&lt;Datagram&gt; result = sendMessageWorker.receive(messages, command); final CompletableFuture&lt;Datagram&gt; future = new CompletableFuture&lt;&gt;(); // Future 回调 Futures.addCallback(result, new FutureCallback&lt;Datagram&gt;() &#123; @Override public void onSuccess(Datagram datagram) &#123; future.complete(datagram); &#125; @Override public void onFailure(Throwable ex) &#123; future.completeExceptionally(ex); &#125; &#125; ); return future;&#125;// sendMessageWorker receiveListenableFuture&lt;Datagram&gt; receive(final List&lt;RawMessage&gt; messages, final RemotingCommand cmd) &#123; final List&lt;SettableFuture&lt;ReceiveResult&gt;&gt; futures = new ArrayList&lt;&gt;(messages.size()); for (final RawMessage message : messages) &#123; final MessageHeader header = message.getHeader(); monitorMessageReceived(header.getCreateTime(), header.getSubject()); final ReceivingMessage receivingMessage = new ReceivingMessage(message, cmd.getReceiveTime()); // 这种异步的处理方式，在QMQ中很多，很多开源产品基本也都是这样做的 futures.add(receivingMessage.promise()); invoker.invoke(receivingMessage); &#125; return Futures.transform(Futures.allAsList(futures), (Function&lt;? super List&lt;ReceiveResult&gt;, ? extends Datagram&gt;) input -&gt; RemotingBuilder.buildResponseDatagram(CommandCode.SUCCESS, cmd.getHeader(), new SendResultPayloadHolder(input)));&#125;// invokeprivate void doInvoke(ReceivingMessage message) &#123; // 设置broker为readOnly，在发布的时候时候，等跌0，这种设置是很有必要的 if (BrokerConfig.isReadonly()) &#123; brokerReadOnly(message); return; &#125;// 当主从同步差异较大时，将broker设置为readOnly if (bigSlaveLag()) &#123; brokerReadOnly(message); return; &#125; final String subject = message.getSubject(); // 非法subject if (isIllegalSubject(subject)) &#123; // 可以配置某个subject直接reject if (isRejectIllegalSubject()) &#123; notAllowed(message); return; &#125; &#125; try &#123; // 就是append message_log ReceiveResult result = messageStore.putMessage(message); // 在这里可以设置当从也同步这条消息完成才认为这条消息发送成功 offer(message, result); &#125; catch (Throwable t) &#123; error(message, t); &#125;&#125; 主要节点我都注释上了，接下来看一下message_log： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798public PutMessageResult putMessage(final RawMessage message) &#123; final AppendMessageResult&lt;MessageSequence&gt; result; LogSegment segment = logManager.latestSegment(); if (segment == null) &#123; segment = logManager.allocNextSegment(); &#125; if (segment == null) &#123; return new PutMessageResult(PutMessageStatus.CREATE_MAPPED_FILE_FAILED, null); &#125; // 主要在messageAppender这里，也可以从这个appender中看下message_log消息格式 result = segment.append(message, messageAppender); switch (result.getStatus()) &#123; case SUCCESS: break; case END_OF_FILE: // 一个segmengt固定大小，这里是到达一个segment末尾，需要新建 LogSegment logSegment = logManager.allocNextSegment(); if (logSegment == null) &#123; return new PutMessageResult(PutMessageStatus.CREATE_MAPPED_FILE_FAILED, null); &#125; return putMessage(message); case MESSAGE_SIZE_EXCEEDED: return new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, result); default: return new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result); &#125; return new PutMessageResult(PutMessageStatus.SUCCESS, result); &#125;// message apender声明private class RawMessageAppender implements MessageAppender&lt;RawMessage, MessageSequence&gt; &#123; private static final int MAX_BYTES = 1024; private static final byte ATTR_EMPTY_RECORD = 1; private static final byte ATTR_MESSAGE_RECORD = 0; private final ByteBuffer workingBuffer = ByteBuffer.allocate(MAX_BYTES); @Override public AppendMessageResult&lt;MessageSequence&gt; doAppend(long baseOffset, ByteBuffer targetBuffer, int freeSpace, RawMessage message) &#123; workingBuffer.clear(); final String subject = message.getHeader().getSubject(); final byte[] subjectBytes = subject.getBytes(StandardCharsets.UTF_8); final long wroteOffset = baseOffset + targetBuffer.position(); final int recordSize = recordSize(subjectBytes.length, message.getBodySize()); // 到达segment末尾，末尾填充 if (recordSize != freeSpace &amp;&amp; recordSize + MIN_RECORD_BYTES &gt; freeSpace) &#123; workingBuffer.limit(MIN_RECORD_BYTES); workingBuffer.putInt(MagicCode.MESSAGE_LOG_MAGIC_V3); // empty消息attribute标识 workingBuffer.put(ATTR_EMPTY_RECORD); workingBuffer.putLong(System.currentTimeMillis()); targetBuffer.put(workingBuffer.array(), 0, MIN_RECORD_BYTES); int fillZeroLen = freeSpace - MIN_RECORD_BYTES; if (fillZeroLen &gt; 0) &#123; targetBuffer.put(fillZero(fillZeroLen)); &#125; return new AppendMessageResult&lt;&gt;(AppendMessageStatus.END_OF_FILE, wroteOffset, freeSpace, null); &#125; else &#123; // 一条消息都会有一个逻辑sequence final long sequence = consumerLogManager.getOffsetOrDefault(subject, 0); int headerSize = recordSize - message.getBodySize(); workingBuffer.limit(headerSize); // QMQ采用crc校验 workingBuffer.putInt(MagicCode.MESSAGE_LOG_MAGIC_V3); // 正常消息attribute标识 workingBuffer.put(ATTR_MESSAGE_RECORD); workingBuffer.putLong(System.currentTimeMillis()); workingBuffer.putLong(sequence); workingBuffer.putShort((short) subjectBytes.length); workingBuffer.put(subjectBytes); workingBuffer.putLong(message.getHeader().getBodyCrc()); workingBuffer.putInt(message.getBodySize()); targetBuffer.put(workingBuffer.array(), 0, headerSize); // payload targetBuffer.put(message.getBody().nioBuffer()); consumerLogManager.incOffset(subject); final long payloadOffset = wroteOffset + headerSize; return new AppendMessageResult&lt;&gt;(AppendMessageStatus.SUCCESS, wroteOffset, recordSize, new MessageSequence(sequence, payloadOffset)); &#125; &#125; private byte[] fillZero(int len) &#123; byte[] zero = new byte[len]; Arrays.fill(zero, (byte) 0); return zero; &#125; &#125;&#125; 在RawMessageAppender中我们也能看到message_log的消息存储格式，QMQ也是采用crc校验消息完整准确性。QMQ发送消息就是以上这些。谢谢。]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QMQ源码分析之delay-server篇【三】]]></title>
    <url>%2F4c5184d3.html</url>
    <content type="text"><![CDATA[前言 上篇我们分析了QMQ delay-server关于存储的部分，这一篇我们会对投递的源码进行分析。 投递投递的相关内容在WheelTickManager这个类。提前加载schedule_log、wheel根据延迟时间到时进行投递等相关工作都在这里完成。而关于真正进行投递的相关类是在sender这个包里。 wheelwheel包里一共就三个类文件，HashWheelTimer、WheelLoadCursor、WheelTickManager，WheelTickManager就应该是wheel加载文件，wheel中的消息到时投递的管理器；WheelLoadCursor应该就是上一篇中提到的schedule_log文件加载到哪里的cursor标识；那么HashWheelTimer就是一个辅助工具类，简单理解成Java中的ScheduledExecutorService，可理解成是根据延迟消息的延迟时间进行投递的timer，所以这里不对这个工具类做更多解读，我们更关心MQ逻辑。首先来看提前一定时间加载schedule_log，这里的提前一定时间是多长时间呢？这个是根据需要配置的，比如3schedule_log的刻度自定义配置为1h，提前加载时间配置为30min，那么在2019-02-10 17:30就应该加载2019021018这个schedule_log。 1234567891011121314@Override public void start() &#123; if (!isStarted()) &#123; sender.init(); // hash wheel timer,内存中的wheel timer.start(); started.set(true); // 根据dispatch log,从上次投递结束的地方恢复开始投递 recover(); // 加载线程，用于加载schedule_log loadScheduler.scheduleWithFixedDelay(this::load, 0, config.getLoadSegmentDelayMinutes(), TimeUnit.MINUTES); LOGGER.info("wheel started."); &#125; &#125; recover这个方法，会根据dispatch log中的投递记录，找到上一次最后投递的位置，在delay-server重启的时候，wheel会根据这个位置恢复投递。 1234567891011121314151617181920212223242526272829303132333435private void recover() &#123; LOGGER.info("wheel recover..."); // 最新的dispatch log segment DispatchLogSegment currentDispatchedSegment = facade.latestDispatchSegment(); if (currentDispatchedSegment == null) &#123; LOGGER.warn("load latest dispatch segment null"); return; &#125; int latestOffset = currentDispatchedSegment.getSegmentBaseOffset(); DispatchLogSegment lastSegment = facade.lowerDispatchSegment(latestOffset); if (null != lastSegment) doRecover(lastSegment); // 根据最新的dispatch log segment进行恢复投递 doRecover(currentDispatchedSegment); LOGGER.info("wheel recover done. currentOffset:&#123;&#125;", latestOffset); &#125;private void doRecover(DispatchLogSegment dispatchLogSegment) &#123; int segmentBaseOffset = dispatchLogSegment.getSegmentBaseOffset(); ScheduleSetSegment setSegment = facade.loadScheduleLogSegment(segmentBaseOffset); if (setSegment == null) &#123; LOGGER.error("load schedule index error,dispatch segment:&#123;&#125;", segmentBaseOffset); return; &#125; // 得到一个关于已投递记录的set LongHashSet dispatchedSet = loadDispatchLog(dispatchLogSegment); // 根据这个set，将最新的dispatch log segment中未投递的消息add in wheel。 WheelLoadCursor.Cursor loadCursor = facade.loadUnDispatch(setSegment, dispatchedSet, this::refresh); int baseOffset = loadCursor.getBaseOffset(); // 记录cursor loadingCursor.shiftCursor(baseOffset, loadCursor.getOffset()); loadedCursor.shiftCursor(baseOffset); &#125; 恢复基本就是以上的这些内容，接下来看看是如何加载的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344 private void load() &#123; // 提前一定时间加载到下一 delay segment long next = System.currentTimeMillis() + config.getLoadInAdvanceTimesInMillis(); int prepareLoadBaseOffset = resolveSegment(next); try &#123; // 加载到prepareLoadBaseOffset这个delay segment loadUntil(prepareLoadBaseOffset); &#125; catch (InterruptedException ignored) &#123; LOGGER.debug("load segment interrupted"); &#125; &#125;private void loadUntil(int until) throws InterruptedException &#123; // 当前wheel已加载到baseOffset int loadedBaseOffset = loadedCursor.baseOffset(); // 如已加载到until，则break // have loaded if (loadedBaseOffset &gt; until) return; do &#123; // 加载失败，则break // wait next turn when loaded error. if (!loadUntilInternal(until)) break; // 当前并没有until这个delay segment，即loading cursor小于until // load successfully(no error happened) and current wheel loading cursor &lt; until if (loadingCursor.baseOffset() &lt; until) &#123; // 阻塞，直到thresholdTime+blockingExitTime // 即如果提前blockingExitTime还未有until这个delay segment的消息进来，则退出 long thresholdTime = System.currentTimeMillis() + config.getLoadBlockingExitTimesInMillis(); // exit in a few minutes in advance if (resolveSegment(thresholdTime) &gt;= until) &#123; loadingCursor.shiftCursor(until); loadedCursor.shiftCursor(until); break; &#125; &#125; // 避免cpu load过高 Thread.sleep(100); &#125; while (loadedCursor.baseOffset() &lt; until); LOGGER.info("wheel load until &#123;&#125; &lt;= &#123;&#125;", loadedCursor.baseOffset(), until); &#125; 根据配置的提前加载时间，内存中的wheel会提前加载schedule_log，加载是在一个while循环里，直到加载到until delay segment才退出，如果当前没有until 这个delay segment，那么会在配置的blockingExitTime时间退出该循环，而为了避免cpu load过高，这里会在每次循环间隔设置100ms sleep。这里加载为什么是在while循环里？以及为什么sleep 100ms，sleep 500ms 或者1s可不可以？以及为什么要设置个blockingExitTime呢？下面的分析之后，应该就能回答这些问题了。主要考虑两种情况，一种是当之前一直没有delay segment或者delay segment是间隔存在的，比如delay segment刻度为1h，2019031001和2019031004之间的2019031002及2019031003不存在这种之类的delay segment不存在的情况，另一种是当正在加载delay segment的时候，位于该segment的延迟消息正在被加载，这种情况是有可能丢消息的。所以这里加载是在一个循环里，以及设置了两个cursor，即loading cursor，和loaded cursor。一个表示正在加载，一个表示已经加载。此外，上面每次循环sleep 100ms，可不可以sleep 500ms 1s？答案是可以，只是消息是否能容忍500ms 或者1s的延迟。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475private boolean loadUntilInternal(int until) &#123; int index = resolveStartIndex(); if (index &lt; 0) return true; try &#123; while (index &lt;= until) &#123; ScheduleSetSegment segment = facade.loadScheduleLogSegment(index); if (segment == null) &#123; int nextIndex = facade.higherScheduleBaseOffset(index); if (nextIndex &lt; 0) return true; index = nextIndex; continue; &#125; // 具体加载某个segment的地方 loadSegment(segment); int nextIndex = facade.higherScheduleBaseOffset(index); if (nextIndex &lt; 0) return true; index = nextIndex; &#125; &#125; catch (Throwable e) &#123; LOGGER.error("wheel load segment failed,currentSegmentOffset:&#123;&#125; until:&#123;&#125;", loadedCursor.baseOffset(), until, e); QMon.loadSegmentFailed(); return false; &#125; return true;&#125;private void loadSegment(ScheduleSetSegment segment) &#123; final long start = System.currentTimeMillis(); try &#123; int baseOffset = segment.getSegmentBaseOffset(); long offset = segment.getWrotePosition(); if (!loadingCursor.shiftCursor(baseOffset, offset)) &#123; LOGGER.error("doLoadSegment error,shift loadingCursor failed,from &#123;&#125;-&#123;&#125; to &#123;&#125;-&#123;&#125;", loadingCursor.baseOffset(), loadingCursor.offset(), baseOffset, offset); return; &#125; WheelLoadCursor.Cursor loadedCursorEntry = loadedCursor.cursor(); // have loaded // 已经加载 if (baseOffset &lt; loadedCursorEntry.getBaseOffset()) return; long startOffset = 0; // last load action happened error // 如果上次加载失败，则从上一次的位置恢复加载 if (baseOffset == loadedCursorEntry.getBaseOffset() &amp;&amp; loadedCursorEntry.getOffset() &gt; -1) startOffset = loadedCursorEntry.getOffset(); LogVisitor&lt;ScheduleIndex&gt; visitor = segment.newVisitor(startOffset, config.getSingleMessageLimitSize()); try &#123; loadedCursor.shiftCursor(baseOffset, startOffset); long currentOffset = startOffset; // 考虑一种情况，当前delay segment正在append消息，所以是while，而loaded cursor的offset也是没加载一个消息更新的 while (currentOffset &lt; offset) &#123; Optional&lt;ScheduleIndex&gt; recordOptional = visitor.nextRecord(); if (!recordOptional.isPresent()) break; ScheduleIndex index = recordOptional.get(); currentOffset = index.getOffset() + index.getSize(); refresh(index); loadedCursor.shiftOffset(currentOffset); &#125; loadedCursor.shiftCursor(baseOffset); LOGGER.info("loaded segment:&#123;&#125; &#123;&#125;", loadedCursor.baseOffset(), currentOffset); &#125; finally &#123; visitor.close(); &#125; &#125; finally &#123; Metrics.timer("loadSegmentTimer").update(System.currentTimeMillis() - start, TimeUnit.MILLISECONDS); &#125;&#125; 还记得上一篇我们提到过，存储的时候，如果这个消息位于正在被wheel加载segment中，那么这个消息应该是会被加载到wheel中的。 12345678910111213141516171819202122232425262728293031private boolean iterateCallback(final ScheduleIndex index) &#123; long scheduleTime = index.getScheduleTime(); long offset = index.getOffset(); // 主要看一下这个canAdd if (wheelTickManager.canAdd(scheduleTime, offset)) &#123; wheelTickManager.addWHeel(index); return true; &#125; return false;&#125;// 就是cursor起作用的地方了public boolean canAdd(long scheduleTime, long offset) &#123; WheelLoadCursor.Cursor currentCursor = loadingCursor.cursor(); int currentBaseOffset = currentCursor.getBaseOffset(); long currentOffset = currentCursor.getOffset();// 根据延迟时间确定该消息位于哪个segment int baseOffset = resolveSegment(scheduleTime); // 小于当前loading cursor,则put int wheel if (baseOffset &lt; currentBaseOffset) return true;// 正在加载 if (baseOffset == currentBaseOffset) &#123; // 根据cursor的offset判断 return currentOffset &lt;= offset; &#125; return false;&#125; sendersender包里结构如下图：通过brokerGroup做分组，根据组批量发送，发送时是多线程发送，每个组互不影响，发送时也会根据实时broker的weight进行选择考虑broker进行发送。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748 @Override public void send(ScheduleIndex index) &#123; if (!BrokerRoleManager.isDelayMaster()) &#123; return; &#125; boolean add; try &#123; long waitTime = Math.abs(sendWaitTime); // 入队 if (waitTime &gt; 0) &#123; add = batchExecutor.addItem(index, waitTime, TimeUnit.MILLISECONDS); &#125; else &#123; add = batchExecutor.addItem(index); &#125; &#125; catch (InterruptedException e) &#123; return; &#125; if (!add) &#123; reject(index); &#125; &#125; @Override public void process(List&lt;ScheduleIndex&gt; indexList) &#123; try &#123; // 发送处理逻辑在senderExecutor里 senderExecutor.execute(indexList, this, brokerService); &#125; catch (Exception e) &#123; LOGGER.error("send message failed,messageSize:&#123;&#125; will retry", indexList.size(), e); retry(indexList); &#125; &#125;// 以下为senderExecutor内容 void execute(final List&lt;ScheduleIndex&gt; indexList, final SenderGroup.ResultHandler handler, final BrokerService brokerService) &#123; // 分组 Map&lt;SenderGroup, List&lt;ScheduleIndex&gt;&gt; groups = groupByBroker(indexList, brokerService); for (Map.Entry&lt;SenderGroup, List&lt;ScheduleIndex&gt;&gt; entry : groups.entrySet()) &#123; doExecute(entry.getKey(), entry.getValue(), handler); &#125; &#125; private void doExecute(final SenderGroup group, final List&lt;ScheduleIndex&gt; list, final SenderGroup.ResultHandler handler) &#123; // 分组发送 group.send(list, sender, handler); &#125; 可以看到，投递时是根据server broker进行分组投递。看一下SenderGroup这个类可以看到，每个组的投递是多线程，互不影响，不会存在某个组的server挂掉，导致其他组无法投递。并且这里如果存在某个组无法投递，重试时会选择其它的server broker进行重试。与此同时，在选择组时，会根据每个server broker的weight进行综合考量，即当前server broker有多少消息量要发送。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// 具体发送的地方 private void send(Sender sender, ResultHandler handler, BrokerGroupInfo groupInfo, String groupName, List&lt;ScheduleIndex&gt; list) &#123; try &#123; long start = System.currentTimeMillis(); List&lt;ScheduleSetRecord&gt; records = store.recoverLogRecord(list); QMon.loadMsgTime(System.currentTimeMillis() - start); Datagram response = sendMessages(records, sender); release(records); monitor(list, groupName); if (response == null) &#123; handler.fail(list); &#125; else &#123; final int responseCode = response.getHeader().getCode(); final Map&lt;String, SendResult&gt; resultMap = getSendResult(response); if (resultMap == null || responseCode != CommandCode.SUCCESS) &#123; if (responseCode == CommandCode.BROKER_REJECT || responseCode == CommandCode.BROKER_ERROR) &#123; // 该组熔断 groupInfo.markFailed(); &#125; monitorSendFail(list, groupInfo.getGroupName()); // 重试 handler.fail(list); return; &#125; Set&lt;String&gt; failedMessageIds = new HashSet&lt;&gt;(); boolean brokerRefreshed = false; for (Map.Entry&lt;String, SendResult&gt; entry : resultMap.entrySet()) &#123; int resultCode = entry.getValue().getCode(); if (resultCode != MessageProducerCode.SUCCESS) &#123; failedMessageIds.add(entry.getKey()); &#125; if (!brokerRefreshed &amp;&amp; resultCode == MessageProducerCode.BROKER_READ_ONLY) &#123; groupInfo.markFailed(); brokerRefreshed = true; &#125; &#125; if (!brokerRefreshed) groupInfo.markSuccess(); // dispatch log 记录在这里产生 handler.success(records, failedMessageIds); &#125; &#125; catch (Throwable e) &#123; LOGGER.error("sender group send batch failed,broker:&#123;&#125;,batch size:&#123;&#125;", groupName, list.size(), e); handler.fail(list); &#125; &#125; 就是以上这些，关于QMQ的delay-server源码分析就是这些了，如果以后有机会会分析一下QMQ的其他模块源码，谢谢。]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QMQ源码分析之delay-server篇【二】]]></title>
    <url>%2F14f2781.html</url>
    <content type="text"><![CDATA[前言 本来是固定时间周六更博，但是昨天失恋了，心情不好，晚了一天。那么上一篇我们梳理了下QMQ延迟消息的主要功能，这一篇在此基础上，对照着功能分析一下源码。 整体结构要了解delay-server源码的一个整体结构，需要我们跟着源码，从初始化开始简单先过一遍。重试化的工作都在startup这个包里，而这个包只有一个ServerWrapper类。结合上一篇的内容，通过这个类就基本能看到delay的一个源码结构。delay-server基于netty，init方法完成初始化工作（端口默认为20801、心跳、wheel等），register方法是向meta-server发起请求，获取自己自己的角色为delay，并开始和meta-server的心跳。startServer方法是开始HashWheel的转动，从上次结束的位置继续message_log的回放，开启netty server。另外在做准备工作时知道QMQ是基于一主一从一备的方式，关于这个sync方法，是开启监听一个端口回应同步拉取动作，如果是从节点还要开始向主节点发起同步拉取动作。当这一切都完成了，那么online方法就执行，表示delay开始上线提供服务了。总结一下两个要点，QMQ是基于netty进行通信，并且采用一主一从一备的方式。 存储关于存储在之前我们也讨论了，delay-server接收到延迟消息，会顺序append到message_log，之后再对message_log进行回放，以生成schedule_log。所以关于存储我们需要关注两个东西，一个是message_log的存储，另一个是schedule_log的生成。 message_log其实message_log的生成很简单，就是顺序append。主要逻辑在qunar.tc.qmq.delay.receiver.Receiver这个类里，大致流程就是关于QMQ自定义协议的一个反序列化，然后再对序列化的单个消息进行存储。如图：主要逻辑在途中标红方法doInvoke中。 1234567891011private void doInvoke(ReceivedDelayMessage message) &#123; // ... try &#123; // 注：这里是进行append的地方 ReceivedResult result = facade.appendMessageLog(message); offer(message, result); &#125; catch (Throwable t) &#123; error(message, t); &#125;&#125; delay存储层相关逻辑都在facade这个类里，初始化时类似消息的校验等工作也都在这里，而message_log的相关操作都在messageLog里。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990@Override public AppendMessageRecordResult append(RawMessageExtend record) &#123; AppendMessageResult&lt;Long&gt; result; // 注：当前最新的一个segment LogSegment segment = logManager.latestSegment(); if (null == segment) &#123; segment = logManager.allocNextSegment(); &#125; if (null == segment) &#123; return new AppendMessageRecordResult(PutMessageStatus.CREATE_MAPPED_FILE_FAILED, null); &#125; // 注：真正进行append的动作是messageAppender result = segment.append(record, messageAppender); switch (result.getStatus()) &#123; case MESSAGE_SIZE_EXCEEDED: return new AppendMessageRecordResult(PutMessageStatus.MESSAGE_ILLEGAL, null); case END_OF_FILE: if (null == logManager.allocNextSegment()) &#123; return new AppendMessageRecordResult(PutMessageStatus.CREATE_MAPPED_FILE_FAILED, null); &#125; return append(record); case SUCCESS: return new AppendMessageRecordResult(PutMessageStatus.SUCCESS, result); default: return new AppendMessageRecordResult(PutMessageStatus.UNKNOWN_ERROR, result); &#125; &#125; // 看一下这个appender，也可以通过这里能看到QMQ的delay message 格式定义 private class DelayRawMessageAppender implements MessageAppender&lt;RawMessageExtend, Long&gt; &#123; private final ReentrantLock lock = new ReentrantLock(); private final ByteBuffer workingBuffer = ByteBuffer.allocate(1024); @Override public AppendMessageResult&lt;Long&gt; doAppend(long baseOffset, ByteBuffer targetBuffer, int freeSpace, RawMessageExtend message) &#123; // 这个lock这里影响不大 lock.lock(); try &#123; workingBuffer.clear(); final String messageId = message.getHeader().getMessageId(); final byte[] messageIdBytes = messageId.getBytes(StandardCharsets.UTF_8); final String subject = message.getHeader().getSubject(); final byte[] subjectBytes = subject.getBytes(StandardCharsets.UTF_8); final long startWroteOffset = baseOffset + targetBuffer.position(); final int recordSize = recordSizeWithCrc(messageIdBytes.length, subjectBytes.length, message.getBodySize()); if (recordSize &gt; config.getSingleMessageLimitSize()) &#123; return new AppendMessageResult&lt;&gt;(AppendMessageStatus.MESSAGE_SIZE_EXCEEDED, startWroteOffset, freeSpace, null); &#125; workingBuffer.flip(); if (recordSize != freeSpace &amp;&amp; recordSize + MIN_RECORD_BYTES &gt; freeSpace) &#123; // 填充 workingBuffer.limit(freeSpace); workingBuffer.putInt(MESSAGE_LOG_MAGIC_V1); workingBuffer.put(MessageLogAttrEnum.ATTR_EMPTY_RECORD.getCode()); workingBuffer.putLong(System.currentTimeMillis()); targetBuffer.put(workingBuffer.array(), 0, freeSpace); return new AppendMessageResult&lt;&gt;(AppendMessageStatus.END_OF_FILE, startWroteOffset, freeSpace, null); &#125; else &#123; int headerSize = recordSize - message.getBodySize(); workingBuffer.limit(headerSize); workingBuffer.putInt(MESSAGE_LOG_MAGIC_V2); workingBuffer.put(MessageLogAttrEnum.ATTR_MESSAGE_RECORD.getCode()); workingBuffer.putLong(System.currentTimeMillis()); // 注意这里，是schedule_time ，即延迟时间 workingBuffer.putLong(message.getScheduleTime()); // sequence,每个brokerGroup应该是唯一的 workingBuffer.putLong(sequence.incrementAndGet()); workingBuffer.putInt(messageIdBytes.length); workingBuffer.put(messageIdBytes); workingBuffer.putInt(subjectBytes.length); workingBuffer.put(subjectBytes); workingBuffer.putLong(message.getHeader().getBodyCrc()); workingBuffer.putInt(message.getBodySize()); targetBuffer.put(workingBuffer.array(), 0, headerSize); targetBuffer.put(message.getBody().nioBuffer()); final long payloadOffset = startWroteOffset + headerSize; return new AppendMessageResult&lt;&gt;(AppendMessageStatus.SUCCESS, startWroteOffset, recordSize, payloadOffset); &#125; &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; 以上基本就是message_log的存储部分，接下来我们来看message_log的回放生成schedule_log。 schedule_logMessageLogReplayer这个类就是控制回放的地方。那么考虑一个问题，下一次重启的时候，我们该从哪里进行回放？QMQ是会有一个回放的offset，这个offset会定时刷盘，下次重启的时候会从这个offset位置开始回放。细节可以看一下下面这段代码块。 123456789101112131415161718192021222324final LogVisitor&lt;LogRecord&gt; visitor = facade.newMessageLogVisitor(iterateFrom.longValue());adjustOffset(visitor);while (true) &#123; final Optional&lt;LogRecord&gt; recordOptional = visitor.nextRecord(); if (recordOptional.isPresent() &amp;&amp; recordOptional.get() == DelayMessageLogVisitor.EMPTY_LOG_RECORD) &#123; break; &#125; recordOptional.ifPresent((record) -&gt; &#123; // post以进行存储 dispatcher.post(record); long checkpoint = record.getStartWroteOffset() + record.getRecordSize(); this.cursor.addAndGet(record.getRecordSize()); facade.updateIterateOffset(checkpoint); &#125;);&#125;iterateFrom.add(visitor.visitedBufferSize());try &#123; TimeUnit.MILLISECONDS.sleep(5);&#125; catch (InterruptedException e) &#123; LOGGER.warn(&quot;message log iterate sleep interrupted&quot;);&#125; 注意这里除了offset还有个cursor，这是为了防止回放失败，sleep 5ms后再次回放的时候从cursor位置开始，避免重复消息。那么我们看一下dispatcher.post这个方法: 12345678910111213@Overridepublic void post(LogRecord event) &#123; // 这里是schedule_log AppendLogResult&lt;ScheduleIndex&gt; result = facade.appendScheduleLog(event); int code = result.getCode(); if (MessageProducerCode.SUCCESS != code) &#123; LOGGER.error(&quot;appendMessageLog schedule log error,log:&#123;&#125; &#123;&#125;,code:&#123;&#125;&quot;, event.getSubject(), event.getMessageId(), code); throw new AppendException(&quot;appendScheduleLogError&quot;); &#125;// 先看这里 iterateCallback.apply(result.getAdditional());&#125; 如以上代码，我们看略过schedule_log的存储，看一下那个callback是几个意思: 12345678910111213private boolean iterateCallback(final ScheduleIndex index) &#123; // 延迟时间 long scheduleTime = index.getScheduleTime(); // 这个offset是startOffset,即在delay_segment中的这个消息的起始位置 long offset = index.getOffset(); // 是否add到内存中的HashWheel if (wheelTickManager.canAdd(scheduleTime, offset)) &#123; wheelTickManager.addWHeel(index); return true; &#125; return false; &#125; 这里的意思是，delay-server接收到消息，会判断一下这个消息是否需要add到内存中的wheel中，以防止丢消息。大家记着有这个事情，在投递小节中我们回过头来再说这里。那么回到facade.appendScheduleLog这个方法，schedule_log相关操作在scheduleLog里： 12345678910111213141516@Override public RecordResult&lt;T&gt; append(LogRecord record) &#123; long scheduleTime = record.getScheduleTime(); // 这里是根据延迟时间定位对应的delaySegment的 DelaySegment&lt;T&gt; segment = locateSegment(scheduleTime); if (null == segment) &#123; segment = allocNewSegment(scheduleTime); &#125; if (null == segment) &#123; return new NopeRecordResult(PutMessageStatus.CREATE_MAPPED_FILE_FAILED); &#125; // 具体动作在append里 return retResult(segment.append(record, appender)); &#125; 留意locateSegment这个方法，它是根据延迟时间定位DelaySegment，比如如果延迟时间是2019-03-03 16:00:00，那么就会定位到201903031600这个DelaySegment（注：这里贴的代码不是最新的，最新的是DelaySegment的刻度是可以配置，到分钟级别）。同样，具体动作也是appender做的，如下: 123456789101112131415161718192021222324@Override public AppendRecordResult&lt;ScheduleSetSequence&gt; appendLog(LogRecord log) &#123; workingBuffer.clear(); workingBuffer.flip(); final byte[] subjectBytes = log.getSubject().getBytes(StandardCharsets.UTF_8); final byte[] messageIdBytes = log.getMessageId().getBytes(StandardCharsets.UTF_8); int recordSize = getRecordSize(log, subjectBytes.length, messageIdBytes.length); workingBuffer.limit(recordSize); long scheduleTime = log.getScheduleTime(); long sequence = log.getSequence(); workingBuffer.putLong(scheduleTime); // message_log中的sequence workingBuffer.putLong(sequence); workingBuffer.putInt(log.getPayloadSize()); workingBuffer.putInt(messageIdBytes.length); workingBuffer.put(messageIdBytes); workingBuffer.putInt(subjectBytes.length); workingBuffer.put(subjectBytes); workingBuffer.put(log.getRecord()); workingBuffer.flip(); ScheduleSetSequence record = new ScheduleSetSequence(scheduleTime, sequence); return new AppendRecordResult&lt;&gt;(AppendMessageStatus.SUCCESS, 0, recordSize, workingBuffer, record); &#125; 这里也能看到schedule_log的消息格式。 发现就写了个存储篇幅就已经挺大了，投递涉及到的内容可能更多，那么关于投递就开个下一篇吧。]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QMQ源码分析之delay-server篇【一】]]></title>
    <url>%2F3159cb59.html</url>
    <content type="text"><![CDATA[前言 QMQ是一款去哪儿网内部使用多年的mq。不久前(大概1-2年前)已在携程投入生产大规模使用，年前这款mq也开源了出来。关于QMQ的相关设计文章可以看这里。在这里，我假设你已经对QMQ前世今生以及其设计和实现等背景知识已经有了一个较为全面的认识。 我的阅读姿势对一款开源产品愈来愈感兴趣，想要了解一款开源产品更多的技术细节的时候，最好的方式自然是去阅读她的源码。那么一个正确阅读开源软件源码的姿势是什么呢？我觉得这完全就像一个相亲过程： 媒婆介绍相亲对象基本信息。这一定是前提。很多人都忽视了这一个步骤。在这个步骤中，要去了解这款开源软件是用来做什么的？解决了什么问题？如何解决这些问题的？所处地位？其实就是what,why,how,where四个问题。要是在阅读源码前能准备下这四个问题的答案，那么接下来阅读源码的工作将更有效果。 见面，喝茶，对媒婆所言一探究竟。这个时候我们要去认识下软件的整体结构，例如，包结构，依赖轻重，主要功能是哪些在哪里等。此外还要去验证下”媒婆所言”是否属实，我们要自己操作运行一下，对这个”姑娘”有一个基础认识。 约会。有以上基础认识之后，就要深入源码一探究竟。针对各功能点(主要是第一个步骤中谈到的解决的什么问题即why)各条线深入下去，最后贯穿起来，形成一个闭环。 自由发挥。这个时候就看缘分了，对上眼就成了contributor，对不上眼也能多个朋友多条路不是。 主要功能对于delay-server，官方已经有了一些介绍。记住，官方通常是最卖力的那个”媒婆”。qmq-delay-server其实主要做的是转发工作。所谓转发，就是delay-server做的就是个存储和投递的工作。怎么理解，就是qmq-client会对消息进行一个路由，即实时消息投递到实时server，延迟消息往delay-server投递，多说一句，这个路由的功能是由qmq-meta-server提供。投递到delay-server的消息会存下来，到时间之后再进行投递。现在我们知道了存储和投递是delay-server主要的两个功能点。那么我们挨个击破: 存储假如让我们来设计实现一个delay-server，存储部分我们需要解决什么问题？我觉得主要是要解决到期投递的到期问题。我们可以用传统db做，但是这个性能肯定是上不去的。我们也可以用基于LSM树的RocksDB。或者，干脆直接用文件存储。QMQ是用文件存储的。而用文件存储是怎么解决到期问题的呢？delay-server接收到延迟消息，就将消息append到message_log中，然后再通过回放这个message_log得到schedule_log，此外还有一个dispatch _log用于记录投递记录。QMQ还有个跟投递相关的存储设计，即两层HashWheel。第一层位于磁盘上，例如，以一个小时一个刻度一个文件，我们叫delay_message_segment，如延迟时间为2019年02月23日 19:00 至2019年02月23日 20:00为延迟消息将被存储在2019022319。并且这个刻度是可以配置调整的。第二层HashWheel位于内存中。也是以一个时间为刻度，比如500ms，加载进内存中的延迟消息文件会根据延迟时间hash到一个HashWheel中，第二层的wheel涉及更多的是下一小节的投递。貌似存储到这里就结束了，然而还有一个问题，目前当投递的时候我们需要将一个delay_message_segment加载进内存中，而假如我们提前一个刻度加载进一个delay_message_segment到内存中的hashwheel，比如在2019年02月23日 18:00加载2019022319这个segment文件，那么一个hashwheel中就会存在两个delay_message_segment，而这个时候所占内存是非常大的，所以这是完全不可接收的。所以，QMQ引入了一个数据结构，叫schedule_index，即消息索引，存储的内容为消息的索引，我们加载到内存的是这个schedule_index，在真正投递的时候再根据索引查到消息体进行投递。 投递解决了存储，那么到期的延迟消息如何投递呢？如在上一小节存储中所提到的，内存中的hashwheel会提前一段时间加载delay_schedule_index，这个时间自然也是可以配置的。而在hashwheel中，默认每500ms会tick一次，这个500ms也是可以根据用户需求配置的。而在投递的时候，QMQ根据实时broker进行分组多线程投递，如果某一broker离线不可用，导致投递失败，delay-server会将延迟消息投递在其他存活的实时broker。其实这里对于实时的broker应该有一个关于投递消息权重的，现在delay-server没有考虑到这一点，不过我看已经有一个pr解决了这个问题，只是官方还没有时间看这个问题。除此之外，QMQ还考虑到了要是当前延迟消息所属的delay_segment已经加载到内存中的hashwheel了，这个时候消息应该是直接投递或也应加载到hashwheel中的。这里需要考虑的情况还是比较多的，比如考虑delay_segment正在加载、已经加载、加载完成等情况，对于这种情况，QMQ用了两个cursor来表示hashwheel加载到哪个delay_segment以及加载到对应segment的什么offset了，这里还是挺复杂的，这里的代码逻辑在WheelTickManager这个类。 我们先来看一看整体结构以功能划分的包结构，算是比较清晰。cleaner是日志清理工作相关，receiver是接收消息相关，sender是投递相关，store是存储相关，sync是同步备份相关，wheel则是hashwheel相关。 关于QMQ源码阅读前的准备工作就先做到这里，下一篇我们就深入源码分析以上提到的各个细节。]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何科学上网？]]></title>
    <url>%2F8c46c59b.html</url>
    <content type="text"><![CDATA[为了给我们提供一个安全的网络环境，所以先驱前辈们建立了一堵墙。总有些调皮 好奇的孩子想要翻过墙去看看墙那边的世界。但是存在风险，需谨慎。 共有下面两种方式供选择： 利用VPN 免费免费的vpn有很多，但是速度、稳定性和流量限制是基本不能满足需要的，所以就不推荐了。 收费收费的vpn一般都在每月10元左右，并且足够稳定。另外，建议大家选择国外的vpn，国内的vpn产商说不定哪天就跑路什么的。在这里，推荐ExpressVPN和PureVPN。前者比较知名，也比较稳健，价格大概在每月$7+；后者也相对比较好用，每月大概在$3+，说是有中国用户的专线。详情可参考。 自建代理喜欢掌握主动权的我，倾向于采用自建代理的方案。综合来看自建代理都是最实惠，最可控的方案。 购买VPS目前VPS产商有两家做的最大，分别是BandwagonHost(搬瓦工)和Vultr。有篇文章对比了这两家厂商的产品。购买VPS都是有优惠的，搬瓦工 Vultr。因为搬瓦工比较老牌，老而弥坚，所以我选择的是它。如果你不喜欢老而弥坚的东西，选择了Vultr，那么请移步看搭建SSR。购买时注意是不是支持中国专线，如果没注意，那么购买成功之后也是可以更改线路的。购买完成，你会受到一封邮件，里边有ip port password等信息，连接上vps，安装完一些基础工具(wget等)，就可以开干了。 搭建代理现在用的最多的就是shadowsocks，以及其衍生版本shadowsocks r。我选择的是shadowsockr。这里有个ssr工具网站，客户端，一键安装脚本在这里都能找到。 ssh连接上vps 依次运行下边三条命令： 1wget --no-check-certificate -O shadowsocks-all.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.sh 1chmod +x shadowsocks-all.sh 1./shadowsocks-all.sh 2&gt;&amp;1 | tee shadowsocks-all.log 接下来按照提示，选择参数安装即可，步骤大概为： 选择版本，建议ShadowsocksR 设置SSR密码 选择SSR服务器端口 选择加密方式如这里选择chacha20，输入对应序号12即可。 选择协议如这里选择auth_aes128_md5，输入对应序号5即可 选择混淆方式如这里选择http_simple，输入对应序号2即可 参数设置完成，任意键开始安装，静静等待。 安装完成，你会看到以上信息，记录下来，待会儿会用到。你也可以在下图文件夹下的config.json看到。客户端安装windows 下载mac下载andriod下载 或者在应用商城看一下有没有shadowsocks-r(或者ssr)客户端下载ios 免费的App可以用Potatso Lite，不过应该需要申请一下美国AppleID安装完毕，输入安装完毕让你记下的那些信息(在/etc/shadowsocks-r/config.json，或者在刚才安装的目录下找到shadowsocks-all.log文件里也有相关信息)。另外，ssr客户端支持二维码扫描，剪贴板导入等方式，很方便，如下图：安卓上效果如下：好了，安卓和ios设备现在基本都能上网了。但是pc端还需要一个东西，即chrome的一个插件，swithy omega。下载插件添加到chrome完毕，配置如下图： 其中的规则列表网址：https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt 详情可以参考gfwlist 就是这些，你可以科学上网了。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>科学上网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018年终总结]]></title>
    <url>%2F59ca7e41.html</url>
    <content type="text"><![CDATA[又到年底，然而今年并不打算再写年终总结。]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
</search>
